{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7054188a",
   "metadata": {},
   "source": [
    "# Set up Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff7a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Set up the model\n",
    "# Parameters from the paper: P=0 (number of components), optimal smoothness lambda_sigma ≈ 1.5\n",
    "\n",
    "# Get the number of neurons from data\n",
    "N = data.shape[0]  # Number of neurons\n",
    "\n",
    "# Initialize processes\n",
    "gp = models.GaussianProcess(kernel=kernel_gp, N=N)\n",
    "wp = models.WishartProcess(kernel=kernel_wp, P=N+1, V=1e-2*jnp.eye(N))  # P=N+1 as per the code\n",
    "\n",
    "# Likelihood model\n",
    "likelihood = models.NormalConditionalLikelihood(N)\n",
    "\n",
    "# Joint distribution\n",
    "joint = models.JointGaussianWishartProcess(gp, wp, likelihood)\n",
    "\n",
    "# %% Cross-validation to select hyperparameters\n",
    "# This is a simplified version - in practice, you'd want to implement a full\n",
    "# cross-validation procedure as mentioned in the paper\n",
    "\n",
    "def perform_cross_validation(x, y, P_values=[0, 1, 2], lambda_values=[0.5, 1.0, 1.5, 2.0]):\n",
    "    \"\"\"\n",
    "    Perform cross-validation to select optimal P and lambda_sigma values.\n",
    "    \n",
    "    In a real implementation, you would:\n",
    "    1. Split data into training and test sets multiple times\n",
    "    2. For each hyperparameter combination, train on training set\n",
    "    3. Evaluate log probability on test set\n",
    "    4. Average results across folds\n",
    "    \"\"\"\n",
    "    print(\"In practice, you would implement a full cross-validation here.\")\n",
    "    print(\"Based on the paper, optimal values were P=0 and lambda_sigma ≈ 1.5\")\n",
    "    \n",
    "    # This would be your actual cross-validation logic\n",
    "    # For demonstration, we'll just return the values mentioned in the paper\n",
    "    return 0, 1.5  # P=0, lambda_sigma=1.5\n",
    "\n",
    "# For demonstration, we'll just use the paper's values\n",
    "P_optimal, lambda_optimal = perform_cross_validation(x, y)\n",
    "print(f\"Selected hyperparameters: P={P_optimal}, lambda_sigma={lambda_optimal}\")\n",
    "\n",
    "# %% Run inference\n",
    "# Initialize variational family\n",
    "varfam = inference.VariationalNormal(joint.model)\n",
    "\n",
    "# Set up optimizer\n",
    "adam = optim.Adam(1e-2)  # Learning rate\n",
    "\n",
    "# Set random seed\n",
    "inference_seed = 2\n",
    "key = jax.random.PRNGKey(inference_seed)\n",
    "\n",
    "# Run variational inference\n",
    "print(\"Running variational inference (this may take a while)...\")\n",
    "varfam.infer(adam, x, y, n_iter=5000, key=key)  # Reduced from 20000 for demonstration\n",
    "joint.update_params(varfam.posterior)\n",
    "\n",
    "# %% Visualize training loss\n",
    "visualizations.plot_loss(\n",
    "    [varfam.losses],\n",
    "    xlabel='Iteration',\n",
    "    ylabel='ELBO',\n",
    "    titlestr='Training Loss',\n",
    "    colors=['k']\n",
    ")\n",
    "\n",
    "# %% Sample from the posterior\n",
    "posterior = models.NormalGaussianWishartPosterior(joint, varfam, x)\n",
    "\n",
    "with numpyro.handlers.seed(rng_seed=inference_seed):\n",
    "    mu_hat, sigma_hat, F_hat = posterior.sample(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936d337d",
   "metadata": {},
   "source": [
    "# Visualise Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59eea3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Visualize results for a few selected neurons/conditions\n",
    "def plot_correlation_matrix(sigma, condition_idx, title):\n",
    "    \"\"\"Plot the correlation matrix for a specific condition\"\"\"\n",
    "    cov_matrix = sigma[condition_idx]\n",
    "    diag = jnp.sqrt(jnp.diag(cov_matrix))\n",
    "    corr_matrix = cov_matrix / jnp.outer(diag, diag)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "    plt.colorbar(label='Correlation')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Neuron')\n",
    "    plt.ylabel('Neuron')\n",
    "    \n",
    "    # Add correlation values as text\n",
    "    for i in range(corr_matrix.shape[0]):\n",
    "        for j in range(corr_matrix.shape[1]):\n",
    "            if i != j:  # Only show off-diagonal elements\n",
    "                plt.text(j, i, f'{corr_matrix[i, j]:.2f}', \n",
    "                         ha='center', va='center', \n",
    "                         color='white' if abs(corr_matrix[i, j]) > 0.5 else 'black')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot correlation matrices for select conditions\n",
    "num_conditions = sigma_hat.shape[0]\n",
    "plot_indices = [0, num_conditions // 2, num_conditions - 1]  # First, middle, last\n",
    "\n",
    "for idx in plot_indices:\n",
    "    angle = conditions[idx][0] * 180 / jnp.pi  # Convert to degrees\n",
    "    sf = conditions[idx][1]\n",
    "    title = f\"Noise Correlation at Angle={angle:.1f}°, SF={sf:.2f}\"\n",
    "    plot_correlation_matrix(sigma_hat, idx, title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811f2615",
   "metadata": {},
   "source": [
    "# Compare other things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd51608a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Compare with empirical correlations for validation\n",
    "def compute_empirical_correlation(data, condition_idx):\n",
    "    \"\"\"Compute empirical correlation matrix for a specific condition\"\"\"\n",
    "    # Extract data for the condition across all trials\n",
    "    condition_data = data_model[:, condition_idx, :]  # trials x neurons\n",
    "    \n",
    "    # Compute correlation matrix\n",
    "    corr_matrix = np.corrcoef(condition_data, rowvar=False)\n",
    "    \n",
    "    return corr_matrix\n",
    "\n",
    "# Compare model and empirical correlations for a selected condition\n",
    "selected_condition = 0\n",
    "model_corr = sigma_hat[selected_condition]\n",
    "diag = jnp.sqrt(jnp.diag(model_corr))\n",
    "model_corr = model_corr / jnp.outer(diag, diag)\n",
    "\n",
    "empirical_corr = compute_empirical_correlation(data, selected_condition)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot model correlation\n",
    "im0 = axes[0].imshow(model_corr, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "axes[0].set_title('Model-Based Correlation')\n",
    "axes[0].set_xlabel('Neuron')\n",
    "axes[0].set_ylabel('Neuron')\n",
    "\n",
    "# Plot empirical correlation\n",
    "im1 = axes[1].imshow(empirical_corr, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "axes[1].set_title('Empirical Correlation')\n",
    "axes[1].set_xlabel('Neuron')\n",
    "\n",
    "# Add colorbar\n",
    "fig.colorbar(im0, ax=axes, label='Correlation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d809658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Create a function to analyze correlations across conditions\n",
    "def analyze_correlation_across_conditions(sigma_hat, conditions):\n",
    "    \"\"\"Analyze how correlations change across conditions\"\"\"\n",
    "    # Calculate average absolute correlation for each condition\n",
    "    avg_correlations = []\n",
    "    \n",
    "    for i in range(sigma_hat.shape[0]):\n",
    "        cov_matrix = sigma_hat[i]\n",
    "        diag = jnp.sqrt(jnp.diag(cov_matrix))\n",
    "        corr_matrix = cov_matrix / jnp.outer(diag, diag)\n",
    "        \n",
    "        # Get off-diagonal elements\n",
    "        mask = ~jnp.eye(corr_matrix.shape[0], dtype=bool)\n",
    "        off_diag = corr_matrix[mask]\n",
    "        \n",
    "        # Calculate average absolute correlation\n",
    "        avg_abs_corr = jnp.mean(jnp.abs(off_diag))\n",
    "        avg_correlations.append(avg_abs_corr)\n",
    "    \n",
    "    # Extract angles and spatial frequencies\n",
    "    angles = conditions[:, 0] * 180 / jnp.pi  # Convert to degrees\n",
    "    sfs = conditions[:, 1]\n",
    "    \n",
    "    # Create a unique identifier for each condition\n",
    "    condition_ids = [f\"{a:.0f}°, SF={s:.2f}\" for a, s in zip(angles, sfs)]\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(range(len(avg_correlations)), avg_correlations)\n",
    "    plt.xticks(range(len(avg_correlations)), condition_ids, rotation=90)\n",
    "    plt.ylabel('Average Absolute Correlation')\n",
    "    plt.title('Noise Correlation Strength Across Conditions')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return avg_correlations\n",
    "\n",
    "# Run the analysis\n",
    "avg_correlations = analyze_correlation_across_conditions(sigma_hat, conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c608e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Create a function to extract specific correlation patterns\n",
    "def extract_correlation_pattern(sigma_hat, conditions, neuron_pair=(0, 1)):\n",
    "    \"\"\"Extract correlation between a specific pair of neurons across conditions\"\"\"\n",
    "    n1, n2 = neuron_pair\n",
    "    \n",
    "    # Extract correlations\n",
    "    correlations = []\n",
    "    for i in range(sigma_hat.shape[0]):\n",
    "        cov_matrix = sigma_hat[i]\n",
    "        diag = jnp.sqrt(jnp.diag(cov_matrix))\n",
    "        corr_matrix = cov_matrix / jnp.outer(diag, diag)\n",
    "        correlations.append(corr_matrix[n1, n2])\n",
    "    \n",
    "    # Reshape to match angles and spatial frequencies grid\n",
    "    angles_count = data.shape[1]\n",
    "    sf_count = data.shape[2]\n",
    "    corr_grid = np.array(correlations).reshape(sf_count, angles_count)\n",
    "    \n",
    "    # Create coordinate grids for plotting\n",
    "    angle_vals = np.linspace(0, 360, angles_count, endpoint=False)\n",
    "    sf_vals = np.linspace(0.1, 5.0, sf_count)\n",
    "    angle_grid, sf_grid = np.meshgrid(angle_vals, sf_vals)\n",
    "    \n",
    "    # Plot as a heatmap\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.pcolormesh(angle_grid, sf_grid, corr_grid, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "    plt.colorbar(label='Correlation')\n",
    "    plt.xlabel('Orientation (degrees)')\n",
    "    plt.ylabel('Spatial Frequency')\n",
    "    plt.title(f'Noise Correlation between Neurons {n1} and {n2}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return corr_grid\n",
    "\n",
    "# Analyze correlation pattern for a pair of neurons\n",
    "corr_pattern = extract_correlation_pattern(sigma_hat, conditions, neuron_pair=(0, 1))\n",
    "\n",
    "# %% Save results\n",
    "def save_results(sigma_hat, mu_hat, conditions):\n",
    "    \"\"\"Save results to disk\"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists('results'):\n",
    "        os.makedirs('results')\n",
    "    \n",
    "    # Convert to numpy for saving\n",
    "    sigma_np = np.array(sigma_hat)\n",
    "    mu_np = np.array(mu_hat)\n",
    "    conditions_np = np.array(conditions)\n",
    "    \n",
    "    # Save\n",
    "    np.save('results/sigma_hat.npy', sigma_np)\n",
    "    np.save('results/mu_hat.npy', mu_np)\n",
    "    np.save('results/conditions.npy', conditions_np)\n",
    "    \n",
    "    print(\"Results saved to 'results' directory\")\n",
    "\n",
    "# Uncomment to save results:\n",
    "# save_results(sigma_hat, mu_hat, conditions)\n",
    "\n",
    "# %% Summary\n",
    "print(\"=== Analysis Complete ===\")\n",
    "print(f\"- Analyzed data with {data.shape[0]} neurons across {data.shape[1]*data.shape[2]} conditions\")\n",
    "print(f\"- Estimated noise correlations using Wishart Process model\")\n",
    "print(f\"- Average absolute correlation across all conditions: {np.mean(avg_correlations):.3f}\")\n",
    "print(\"- Results can be further analyzed by neuron pairs, conditions, or other factors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f428546a",
   "metadata": {},
   "source": [
    "# Fisher Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9fab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Fisher Information Calculation with Wishart Process\n",
    "# =====================================================\n",
    "#\n",
    "# This notebook implements Fisher Information calculation for neural data\n",
    "# using the posterior distributions from a Wishart Process model.\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, vmap, jacfwd, jacrev\n",
    "# %% Define Helper Functions for Fisher Information Calculation\n",
    "\n",
    "def compute_gradient(func, x):\n",
    "    \"\"\"\n",
    "    Compute the gradient of a function with respect to inputs x\n",
    "    \n",
    "    Args:\n",
    "        func: The function to differentiate\n",
    "        x: The point at which to evaluate the gradient\n",
    "        \n",
    "    Returns:\n",
    "        The gradient of func at x\n",
    "    \"\"\"\n",
    "    return grad(func)(x)\n",
    "\n",
    "def compute_hessian(func, x):\n",
    "    \"\"\"\n",
    "    Compute the Hessian matrix (second derivatives) of a function\n",
    "    \n",
    "    Args:\n",
    "        func: The function to differentiate\n",
    "        x: The point at which to evaluate the Hessian\n",
    "        \n",
    "    Returns:\n",
    "        The Hessian matrix of func at x\n",
    "    \"\"\"\n",
    "    return jacfwd(jacrev(func))(x)\n",
    "\n",
    "# %% Load Posterior Model from Previous Analysis\n",
    "# This assumes you've run the previous notebook and have saved results\n",
    "\n",
    "def load_posterior_model(result_path=\"results\"):\n",
    "    \"\"\"Load posterior model parameters from saved results\"\"\"\n",
    "    try:\n",
    "        mu_hat = jnp.array(np.load(os.path.join(result_path, \"mu_hat.npy\")))\n",
    "        sigma_hat = jnp.array(np.load(os.path.join(result_path, \"sigma_hat.npy\")))\n",
    "        conditions = jnp.array(np.load(os.path.join(result_path, \"conditions.npy\")))\n",
    "        print(\"Loaded saved posterior model\")\n",
    "        return mu_hat, sigma_hat, conditions\n",
    "    except:\n",
    "        print(\"Saved results not found. Generating synthetic data instead.\")\n",
    "        # Create synthetic data for demonstration\n",
    "        N = 10  # Number of neurons\n",
    "        C = 20  # Number of conditions\n",
    "        \n",
    "        # Create a condition space (e.g., angles from 0 to 2π)\n",
    "        conditions = jnp.linspace(0, 2*jnp.pi, C).reshape(-1, 1)\n",
    "        \n",
    "        # Create synthetic mean responses\n",
    "        mu_hat = jnp.zeros((C, N))\n",
    "        for i in range(N):\n",
    "            mu_hat = mu_hat.at[:, i].set(2*jnp.sin(conditions[:, 0] + i*0.5))\n",
    "        \n",
    "        # Create synthetic covariance matrices\n",
    "        base_sigma = jnp.eye(N) * 0.5\n",
    "        for i in range(N):\n",
    "            for j in range(i+1, N):\n",
    "                base_sigma = base_sigma.at[i, j].set(0.1)\n",
    "                base_sigma = base_sigma.at[j, i].set(0.1)\n",
    "        \n",
    "        sigma_hat = jnp.array([base_sigma * (1 + 0.5*jnp.sin(conditions[i, 0])) for i in range(C)])\n",
    "        \n",
    "        return mu_hat, sigma_hat, conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e16cdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Augment the data with additional interpolated points for better gradient estimation\n",
    "\n",
    "def interpolate_posterior(mu_hat, sigma_hat, conditions, interp_factor=5):\n",
    "    \"\"\"\n",
    "    Interpolate the posterior distribution to get smoother gradients\n",
    "    \n",
    "    Args:\n",
    "        mu_hat: Mean estimates at original conditions\n",
    "        sigma_hat: Covariance estimates at original conditions\n",
    "        conditions: Original condition points\n",
    "        interp_factor: Factor by which to increase density of points\n",
    "        \n",
    "    Returns:\n",
    "        Interpolated means, covariances, and conditions\n",
    "    \"\"\"\n",
    "    if conditions.shape[1] == 1:  # 1D condition space (e.g., just angles)\n",
    "        # Create a finer grid of conditions\n",
    "        min_cond = jnp.min(conditions)\n",
    "        max_cond = jnp.max(conditions)\n",
    "        fine_conditions = jnp.linspace(min_cond, max_cond, \n",
    "                                       (conditions.shape[0]-1)*interp_factor + 1).reshape(-1, 1)\n",
    "        \n",
    "        # Use JAX interpolation for the means (neurons × conditions)\n",
    "        N = mu_hat.shape[1]  # Number of neurons\n",
    "        interp_mu = jnp.zeros((fine_conditions.shape[0], N))\n",
    "        \n",
    "        # Interpolate each neuron's response\n",
    "        for n in range(N):\n",
    "            # Linear interpolation for each neuron\n",
    "            interp_mu = interp_mu.at[:, n].set(\n",
    "                jnp.interp(fine_conditions[:, 0], conditions[:, 0], mu_hat[:, n])\n",
    "            )\n",
    "        \n",
    "        # Interpolate covariances\n",
    "        # This is trickier - for each i,j pair in the covariance matrix\n",
    "        interp_sigma = jnp.zeros((fine_conditions.shape[0], N, N))\n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                interp_sigma = interp_sigma.at[:, i, j].set(\n",
    "                    jnp.interp(fine_conditions[:, 0], conditions[:, 0], sigma_hat[:, i, j])\n",
    "                )\n",
    "                \n",
    "        return interp_mu, interp_sigma, fine_conditions\n",
    "    \n",
    "    elif conditions.shape[1] == 2:  # 2D condition space (e.g., angle and spatial frequency)\n",
    "        print(\"2D interpolation not implemented in this demo. Using original data.\")\n",
    "        return mu_hat, sigma_hat, conditions\n",
    "    \n",
    "    else:\n",
    "        print(\"Higher-dimensional interpolation not implemented. Using original data.\")\n",
    "        return mu_hat, sigma_hat, conditions\n",
    "\n",
    "# %% Compute Fisher Information\n",
    "\n",
    "def compute_fisher_information_single_point(mu_hat, sigma_hat, mu_grad, sigma_grad):\n",
    "    \"\"\"\n",
    "    Compute Fisher Information at a single condition point\n",
    "    \n",
    "    Args:\n",
    "        mu_hat: Mean vector at this condition\n",
    "        sigma_hat: Covariance matrix at this condition\n",
    "        mu_grad: Gradient of mean vector w.r.t. condition\n",
    "        sigma_grad: Gradient of covariance matrix w.r.t. condition\n",
    "        \n",
    "    Returns:\n",
    "        Fisher Information value at this point\n",
    "    \"\"\"\n",
    "    # Invert covariance matrix\n",
    "    sigma_inv = jnp.linalg.inv(sigma_hat)\n",
    "    \n",
    "    # First term: μ′(x)ᵀ Σ⁻¹(x) μ′(x)\n",
    "    first_term = mu_grad.T @ sigma_inv @ mu_grad\n",
    "    \n",
    "    # Second term: (1/2) tr([Σ⁻¹(x)Σ′(x)]²)\n",
    "    sigma_inv_sigma_grad = sigma_inv @ sigma_grad\n",
    "    second_term = 0.5 * jnp.trace(sigma_inv_sigma_grad @ sigma_inv_sigma_grad)\n",
    "    \n",
    "    # Total Fisher Information\n",
    "    fi = first_term + second_term\n",
    "    \n",
    "    return fi\n",
    "\n",
    "def estimate_gradients(mu_hat, sigma_hat, conditions):\n",
    "    \"\"\"\n",
    "    Estimate the gradients of the mean and covariance with respect to conditions\n",
    "    using finite differences\n",
    "    \n",
    "    Args:\n",
    "        mu_hat: Posterior mean estimates (conditions × neurons)\n",
    "        sigma_hat: Posterior covariance estimates (conditions × neurons × neurons)\n",
    "        conditions: Condition points\n",
    "        \n",
    "    Returns:\n",
    "        Gradients of mean and covariance at each condition point\n",
    "    \"\"\"\n",
    "    C, N = mu_hat.shape  # C conditions, N neurons\n",
    "    \n",
    "    if conditions.shape[1] == 1:  # 1D condition space\n",
    "        # Compute gradient using central differences\n",
    "        mu_grad = jnp.zeros((C, N))\n",
    "        sigma_grad = jnp.zeros((C, N, N))\n",
    "        \n",
    "        # For interior points\n",
    "        for i in range(1, C-1):\n",
    "            # Gradient of mean\n",
    "            mu_grad = mu_grad.at[i].set(\n",
    "                (mu_hat[i+1] - mu_hat[i-1]) / (conditions[i+1, 0] - conditions[i-1, 0])\n",
    "            )\n",
    "            \n",
    "            # Gradient of covariance\n",
    "            sigma_grad = sigma_grad.at[i].set(\n",
    "                (sigma_hat[i+1] - sigma_hat[i-1]) / (conditions[i+1, 0] - conditions[i-1, 0])\n",
    "            )\n",
    "        \n",
    "        # For boundary points, use forward/backward differences\n",
    "        # First point\n",
    "        mu_grad = mu_grad.at[0].set(\n",
    "            (mu_hat[1] - mu_hat[0]) / (conditions[1, 0] - conditions[0, 0])\n",
    "        )\n",
    "        sigma_grad = sigma_grad.at[0].set(\n",
    "            (sigma_hat[1] - sigma_hat[0]) / (conditions[1, 0] - conditions[0, 0])\n",
    "        )\n",
    "        \n",
    "        # Last point\n",
    "        mu_grad = mu_grad.at[C-1].set(\n",
    "            (mu_hat[C-1] - mu_hat[C-2]) / (conditions[C-1, 0] - conditions[C-2, 0])\n",
    "        )\n",
    "        sigma_grad = sigma_grad.at[C-1].set(\n",
    "            (sigma_hat[C-1] - sigma_hat[C-2]) / (conditions[C-1, 0] - conditions[C-2, 0])\n",
    "        )\n",
    "        \n",
    "        return mu_grad, sigma_grad\n",
    "    \n",
    "    elif conditions.shape[1] == 2:  # 2D condition space\n",
    "        # For 2D, we need separate gradients for each dimension\n",
    "        # This would be a more complex implementation\n",
    "        # For simplicity in this demo, we'll use a placeholder implementation\n",
    "        print(\"2D gradient estimation simplification used: computing only along first dimension\")\n",
    "        \n",
    "        # Simplified: just compute gradient along first dimension \n",
    "        # In a real implementation, you would compute the full gradient vector\n",
    "        mu_grad = jnp.zeros((C, N))\n",
    "        sigma_grad = jnp.zeros((C, N, N))\n",
    "        \n",
    "        # Sort conditions by first dimension\n",
    "        sort_idx = jnp.argsort(conditions[:, 0])\n",
    "        sorted_conditions = conditions[sort_idx]\n",
    "        sorted_mu = mu_hat[sort_idx]\n",
    "        sorted_sigma = sigma_hat[sort_idx]\n",
    "        \n",
    "        # Now compute gradients as in 1D case\n",
    "        for i in range(1, C-1):\n",
    "            # Gradient of mean\n",
    "            mu_grad = mu_grad.at[sort_idx[i]].set(\n",
    "                (sorted_mu[i+1] - sorted_mu[i-1]) / \n",
    "                (sorted_conditions[i+1, 0] - sorted_conditions[i-1, 0])\n",
    "            )\n",
    "            \n",
    "            # Gradient of covariance\n",
    "            sigma_grad = sigma_grad.at[sort_idx[i]].set(\n",
    "                (sorted_sigma[i+1] - sorted_sigma[i-1]) / \n",
    "                (sorted_conditions[i+1, 0] - sorted_conditions[i-1, 0])\n",
    "            )\n",
    "        \n",
    "        return mu_grad, sigma_grad\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Higher-dimensional gradient estimation not implemented\")\n",
    "\n",
    "def compute_fisher_information(mu_hat, sigma_hat, conditions):\n",
    "    \"\"\"\n",
    "    Compute Fisher Information across all condition points\n",
    "    \n",
    "    Args:\n",
    "        mu_hat: Posterior mean estimates (conditions × neurons)\n",
    "        sigma_hat: Posterior covariance estimates (conditions × neurons × neurons)\n",
    "        conditions: Condition points\n",
    "        \n",
    "    Returns:\n",
    "        Fisher Information at each condition point\n",
    "    \"\"\"\n",
    "    # Get gradients\n",
    "    mu_grad, sigma_grad = estimate_gradients(mu_hat, sigma_hat, conditions)\n",
    "    \n",
    "    # Compute FI at each point\n",
    "    C = conditions.shape[0]  # Number of conditions\n",
    "    fi = jnp.zeros(C)\n",
    "    \n",
    "    for i in range(C):\n",
    "        fi = fi.at[i].set(\n",
    "            compute_fisher_information_single_point(\n",
    "                mu_hat[i], sigma_hat[i], mu_grad[i], sigma_grad[i]\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    return fi, mu_grad, sigma_grad\n",
    "\n",
    "# %% Sample-based Fisher Information with uncertainty\n",
    "\n",
    "def sample_posterior_gradients(joint, varfam, conditions, n_samples=50):\n",
    "    \"\"\"\n",
    "    Sample from the posterior distribution of mean and covariance gradients\n",
    "    to estimate uncertainty in Fisher Information\n",
    "    \n",
    "    Args:\n",
    "        joint: Joint Gaussian-Wishart Process model\n",
    "        varfam: Fitted variational family\n",
    "        conditions: Condition points\n",
    "        n_samples: Number of posterior samples\n",
    "        \n",
    "    Returns:\n",
    "        Samples of Fisher Information at each condition point\n",
    "    \"\"\"\n",
    "    print(\"Not implemented in this demo - requires access to the model posterior\")\n",
    "    \n",
    "    # In a real implementation, this would:\n",
    "    # 1. Sample multiple times from the posterior over μ and Σ\n",
    "    # 2. For each sample, calculate gradients and FI\n",
    "    # 3. Use the distribution of samples to estimate uncertainty\n",
    "\n",
    "    # Placeholder\n",
    "    C = conditions.shape[0]\n",
    "    return jnp.zeros((n_samples, C))\n",
    "\n",
    "# %% Main Analysis\n",
    "\n",
    "# Load or generate data\n",
    "mu_hat, sigma_hat, conditions = load_posterior_model()\n",
    "\n",
    "# Interpolate for better gradient estimation\n",
    "interp_mu, interp_sigma, interp_conditions = interpolate_posterior(mu_hat, sigma_hat, conditions)\n",
    "\n",
    "# Compute Fisher Information\n",
    "fi, mu_grad, sigma_grad = compute_fisher_information(interp_mu, interp_sigma, interp_conditions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3f5f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Visualize results\n",
    "def visualize_fisher_information(fi, conditions):\n",
    "    \"\"\"Visualize Fisher Information across conditions\"\"\"\n",
    "    \n",
    "    if conditions.shape[1] == 1:  # 1D condition space\n",
    "        # Sort by condition value for proper plotting\n",
    "        sort_idx = jnp.argsort(conditions[:, 0])\n",
    "        sorted_fi = fi[sort_idx]\n",
    "        sorted_conditions = conditions[sort_idx, 0]\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(sorted_conditions, sorted_fi, 'b-', linewidth=2)\n",
    "        plt.fill_between(sorted_conditions, \n",
    "                         sorted_fi - sorted_fi*0.2, \n",
    "                         sorted_fi + sorted_fi*0.2, \n",
    "                         alpha=0.3, color='blue',\n",
    "                         label='Approximate uncertainty')\n",
    "        \n",
    "        if sorted_conditions[0] >= 0 and sorted_conditions[-1] <= 2*np.pi + 0.1:\n",
    "            # If conditions appear to be angles\n",
    "            plt.xlabel('Angle (radians)')\n",
    "            plt.xticks(np.linspace(0, 2*np.pi, 5), \n",
    "                      ['0', 'π/2', 'π', '3π/2', '2π'])\n",
    "        else:\n",
    "            plt.xlabel('Condition')\n",
    "            \n",
    "        plt.ylabel('Fisher Information')\n",
    "        plt.title('Fisher Information Across Conditions')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    elif conditions.shape[1] == 2:  # 2D condition space\n",
    "        # For 2D conditions like (angle, spatial frequency)\n",
    "        # Extract unique values for each dimension\n",
    "        angles = np.unique(conditions[:, 0])\n",
    "        sfs = np.unique(conditions[:, 1])\n",
    "        \n",
    "        # Reshape FI into a grid\n",
    "        fi_grid = np.zeros((len(sfs), len(angles)))\n",
    "        \n",
    "        # Map each condition point to its grid position\n",
    "        for i, condition in enumerate(conditions):\n",
    "            angle_idx = np.where(angles == condition[0])[0][0]\n",
    "            sf_idx = np.where(sfs == condition[1])[0][0]\n",
    "            fi_grid[sf_idx, angle_idx] = fi[i]\n",
    "        \n",
    "        # Create a heatmap\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.pcolormesh(angles, sfs, fi_grid, cmap='viridis', shading='auto')\n",
    "        plt.colorbar(label='Fisher Information')\n",
    "        \n",
    "        if angles[0] >= 0 and angles[-1] <= 2*np.pi + 0.1:\n",
    "            # If first dimension appears to be angles\n",
    "            plt.xlabel('Angle (radians)')\n",
    "            plt.xticks(np.linspace(0, 2*np.pi, 5), \n",
    "                      ['0', 'π/2', 'π', '3π/2', '2π'])\n",
    "        else:\n",
    "            plt.xlabel('Condition Dimension 1')\n",
    "            \n",
    "        plt.ylabel('Spatial Frequency' if conditions.shape[1] == 2 else 'Condition Dimension 2')\n",
    "        plt.title('Fisher Information Across Condition Space')\n",
    "        plt.show()\n",
    "    \n",
    "    else:\n",
    "        print(f\"Visualization for {conditions.shape[1]}D condition space not implemented\")\n",
    "\n",
    "# Visualize Fisher Information\n",
    "visualize_fisher_information(fi, interp_conditions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fe2cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Fisher Information Integration for Discriminability\n",
    "\n",
    "def analyze_discriminability(fi, conditions, dimension=0):\n",
    "    \"\"\"\n",
    "    Analyze discriminability between condition pairs based on Fisher Information\n",
    "    \n",
    "    Args:\n",
    "        fi: Fisher Information at each condition\n",
    "        conditions: Condition points\n",
    "        dimension: Dimension along which to compute discriminability (for multi-dimensional conditions)\n",
    "        \n",
    "    Returns:\n",
    "        Discriminability matrix showing JND (Just Noticeable Difference) between conditions\n",
    "    \"\"\"\n",
    "    # Extract conditions along the specified dimension\n",
    "    cond_values = conditions[:, dimension]\n",
    "    \n",
    "    # Sort by condition value\n",
    "    sort_idx = jnp.argsort(cond_values)\n",
    "    sorted_fi = fi[sort_idx]\n",
    "    sorted_conds = cond_values[sort_idx]\n",
    "    \n",
    "    # Compute discriminability matrix based on integrated Fisher Information\n",
    "    C = len(sorted_conds)\n",
    "    disc_matrix = jnp.zeros((C, C))\n",
    "    \n",
    "    for i in range(C):\n",
    "        for j in range(i+1, C):\n",
    "            # For each pair of conditions, compute integrated FI\n",
    "            # We use a simple trapezoidal integration here\n",
    "            segment_indices = list(range(i, j+1))\n",
    "            segment_fi = sorted_fi[segment_indices]\n",
    "            segment_conds = sorted_conds[segment_indices]\n",
    "            \n",
    "            # Integrate FI along the path from condition i to j\n",
    "            # d'² = ∫ FI(x) dx between i and j\n",
    "            disc_squared = 0\n",
    "            for k in range(len(segment_indices)-1):\n",
    "                # Trapezoidal rule\n",
    "                avg_fi = (segment_fi[k] + segment_fi[k+1]) / 2\n",
    "                delta_x = segment_conds[k+1] - segment_conds[k]\n",
    "                disc_squared += avg_fi * delta_x\n",
    "            \n",
    "            # Convert to discriminability (d')\n",
    "            discriminability = jnp.sqrt(disc_squared)\n",
    "            disc_matrix = disc_matrix.at[i, j].set(discriminability)\n",
    "            disc_matrix = disc_matrix.at[j, i].set(discriminability)  # Symmetric\n",
    "    \n",
    "    # Convert to JND (Just Noticeable Difference)\n",
    "    # Define a threshold for discriminability (e.g., d'=1)\n",
    "    threshold = 1.0\n",
    "    jnd_matrix = disc_matrix / threshold\n",
    "    \n",
    "    # Visualize the discriminability matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(jnd_matrix, origin='lower', cmap='viridis')\n",
    "    plt.colorbar(label='JND (d\\'/threshold)')\n",
    "    plt.xlabel('Condition Index')\n",
    "    plt.ylabel('Condition Index')\n",
    "    plt.title('Just Noticeable Difference Between Conditions')\n",
    "    \n",
    "    # Add condition values to ticks (if not too many)\n",
    "    if C <= 10:\n",
    "        plt.xticks(range(C), [f\"{x:.2f}\" for x in sorted_conds])\n",
    "        plt.yticks(range(C), [f\"{x:.2f}\" for x in sorted_conds])\n",
    "    else:\n",
    "        # Show only a subset of ticks\n",
    "        tick_indices = np.linspace(0, C-1, 5, dtype=int)\n",
    "        plt.xticks(tick_indices, [f\"{sorted_conds[i]:.2f}\" for i in tick_indices])\n",
    "        plt.yticks(tick_indices, [f\"{sorted_conds[i]:.2f}\" for i in tick_indices])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return jnd_matrix\n",
    "\n",
    "# Analyze discriminability\n",
    "jnd_matrix = analyze_discriminability(fi, interp_conditions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015cc7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% Analyze contribution of mean gradients vs. covariance gradients\n",
    "\n",
    "def analyze_fi_components(mu_hat, sigma_hat, mu_grad, sigma_grad, conditions):\n",
    "    \"\"\"\n",
    "    Analyze the separate contributions to Fisher Information from\n",
    "    mean gradients and covariance gradients\n",
    "    \"\"\"\n",
    "    C = conditions.shape[0]\n",
    "    fi_mean = jnp.zeros(C)  # Component from mean gradients\n",
    "    fi_cov = jnp.zeros(C)   # Component from covariance gradients\n",
    "    \n",
    "    for i in range(C):\n",
    "        # Contribution from mean gradients: μ′(x)ᵀ Σ⁻¹(x) μ′(x)\n",
    "        sigma_inv = jnp.linalg.inv(sigma_hat[i])\n",
    "        fi_mean = fi_mean.at[i].set(mu_grad[i].T @ sigma_inv @ mu_grad[i])\n",
    "        \n",
    "        # Contribution from covariance gradients: (1/2) tr([Σ⁻¹(x)Σ′(x)]²)\n",
    "        sigma_inv_sigma_grad = sigma_inv @ sigma_grad[i]\n",
    "        fi_cov = fi_cov.at[i].set(0.5 * jnp.trace(sigma_inv_sigma_grad @ sigma_inv_sigma_grad))\n",
    "    \n",
    "    # Sort by condition for proper plotting\n",
    "    if conditions.shape[1] == 1:  # 1D condition space\n",
    "        sort_idx = jnp.argsort(conditions[:, 0])\n",
    "        sorted_fi_mean = fi_mean[sort_idx]\n",
    "        sorted_fi_cov = fi_cov[sort_idx]\n",
    "        sorted_fi_total = sorted_fi_mean + sorted_fi_cov\n",
    "        sorted_conditions = conditions[sort_idx, 0]\n",
    "        \n",
    "        # Plot components\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(sorted_conditions, sorted_fi_total, 'k-', linewidth=2, label='Total FI')\n",
    "        plt.plot(sorted_conditions, sorted_fi_mean, 'b--', linewidth=2, label='Mean component')\n",
    "        plt.plot(sorted_conditions, sorted_fi_cov, 'r--', linewidth=2, label='Covariance component')\n",
    "        \n",
    "        if sorted_conditions[0] >= 0 and sorted_conditions[-1] <= 2*np.pi + 0.1:\n",
    "            # If conditions appear to be angles\n",
    "            plt.xlabel('Angle (radians)')\n",
    "            plt.xticks(np.linspace(0, 2*np.pi, 5), \n",
    "                      ['0', 'π/2', 'π', '3π/2', '2π'])\n",
    "        else:\n",
    "            plt.xlabel('Condition')\n",
    "            \n",
    "        plt.ylabel('Fisher Information')\n",
    "        plt.title('Components of Fisher Information')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        # Show relative contribution\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.stackplot(sorted_conditions, \n",
    "                     [sorted_fi_mean / sorted_fi_total, sorted_fi_cov / sorted_fi_total],\n",
    "                     labels=['Mean component', 'Covariance component'],\n",
    "                     colors=['blue', 'red'], alpha=0.7)\n",
    "        \n",
    "        if sorted_conditions[0] >= 0 and sorted_conditions[-1] <= 2*np.pi + 0.1:\n",
    "            plt.xlabel('Angle (radians)')\n",
    "            plt.xticks(np.linspace(0, 2*np.pi, 5), \n",
    "                      ['0', 'π/2', 'π', '3π/2', '2π'])\n",
    "        else:\n",
    "            plt.xlabel('Condition')\n",
    "            \n",
    "        plt.ylabel('Relative Contribution')\n",
    "        plt.title('Relative Contribution to Fisher Information')\n",
    "        plt.ylim(0, 1)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.show()\n",
    "    \n",
    "    return fi_mean, fi_cov\n",
    "\n",
    "# Analyze components\n",
    "fi_mean, fi_cov = analyze_fi_components(interp_mu, interp_sigma, mu_grad, sigma_grad, interp_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0f8f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Compare Fisher Information under different noise correlation assumptions\n",
    "\n",
    "def compare_fi_correlation_impact(mu_hat, sigma_hat, mu_grad, sigma_grad, conditions):\n",
    "    \"\"\"\n",
    "    Compare Fisher Information under different noise correlation assumptions:\n",
    "    - Full covariance (with correlations)\n",
    "    - Diagonal covariance (no correlations)\n",
    "    - Uniform correlation (same correlation for all pairs)\n",
    "    \"\"\"\n",
    "    C = conditions.shape[0]\n",
    "    N = mu_hat.shape[1]  # Number of neurons\n",
    "    \n",
    "    fi_full = jnp.zeros(C)      # Original FI with full correlation structure\n",
    "    fi_diag = jnp.zeros(C)      # FI with diagonal covariance (no correlations)\n",
    "    fi_uniform = jnp.zeros(C)   # FI with uniform correlation\n",
    "    \n",
    "    # Typical uniform correlation value (could be computed from data)\n",
    "    r_uniform = 0.2\n",
    "    \n",
    "    for i in range(C):\n",
    "        # Full correlation FI (original)\n",
    "        sigma_inv_full = jnp.linalg.inv(sigma_hat[i])\n",
    "        fi_full = fi_full.at[i].set(mu_grad[i].T @ sigma_inv_full @ mu_grad[i])\n",
    "        \n",
    "        # Diagonal covariance (no correlations)\n",
    "        sigma_diag = jnp.diag(jnp.diag(sigma_hat[i]))\n",
    "        sigma_inv_diag = jnp.linalg.inv(sigma_diag)\n",
    "        fi_diag = fi_diag.at[i].set(mu_grad[i].T @ sigma_inv_diag @ mu_grad[i])\n",
    "        \n",
    "        # Uniform correlation\n",
    "        variances = jnp.diag(sigma_hat[i])\n",
    "        sigma_uniform = jnp.zeros_like(sigma_hat[i])\n",
    "        for j in range(N):\n",
    "            for k in range(N):\n",
    "                if j == k:\n",
    "                    sigma_uniform = sigma_uniform.at[j, k].set(variances[j])\n",
    "                else:\n",
    "                    sigma_uniform = sigma_uniform.at[j, k].set(r_uniform * jnp.sqrt(variances[j] * variances[k]))\n",
    "        \n",
    "        sigma_inv_uniform = jnp.linalg.inv(sigma_uniform)\n",
    "        fi_uniform = fi_uniform.at[i].set(mu_grad[i].T @ sigma_inv_uniform @ mu_grad[i])\n",
    "    \n",
    "    # Sort by condition for proper plotting\n",
    "    if conditions.shape[1] == 1:  # 1D condition space\n",
    "        sort_idx = jnp.argsort(conditions[:, 0])\n",
    "        sorted_fi_full = fi_full[sort_idx]\n",
    "        sorted_fi_diag = fi_diag[sort_idx]\n",
    "        sorted_fi_uniform = fi_uniform[sort_idx]\n",
    "        sorted_conditions = conditions[sort_idx, 0]\n",
    "        \n",
    "        # Plot comparison\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(sorted_conditions, sorted_fi_full, 'b-', linewidth=2, label='Full correlations')\n",
    "        plt.plot(sorted_conditions, sorted_fi_diag, 'r--', linewidth=2, label='No correlations')\n",
    "        plt.plot(sorted_conditions, sorted_fi_uniform, 'g-.', linewidth=2, label=f'Uniform correlation (r={r_uniform})')\n",
    "        \n",
    "        if sorted_conditions[0] >= 0 and sorted_conditions[-1] <= 2*np.pi + 0.1:\n",
    "            # If conditions appear to be angles\n",
    "            plt.xlabel('Angle (radians)')\n",
    "            plt.xticks(np.linspace(0, 2*np.pi, 5), \n",
    "                      ['0', 'π/2', 'π', '3π/2', '2π'])\n",
    "        else:\n",
    "            plt.xlabel('Condition')\n",
    "            \n",
    "        plt.ylabel('Fisher Information')\n",
    "        plt.title('Impact of Noise Correlations on Fisher Information')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot relative FI\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(sorted_conditions, sorted_fi_diag / sorted_fi_full, 'r--', linewidth=2, \n",
    "                label='No correlations / Full correlations')\n",
    "        plt.plot(sorted_conditions, sorted_fi_uniform / sorted_fi_full, 'g-.', linewidth=2, \n",
    "                label=f'Uniform correlation / Full correlations')\n",
    "        plt.axhline(y=1, color='k', linestyle='-', alpha=0.5)\n",
    "        \n",
    "        if sorted_conditions[0] >= 0 and sorted_conditions[-1] <= 2*np.pi + 0.1:\n",
    "            plt.xlabel('Angle (radians)')\n",
    "            plt.xticks(np.linspace(0, 2*np.pi, 5), \n",
    "                      ['0', 'π/2', 'π', '3π/2', '2π'])\n",
    "        else:\n",
    "            plt.xlabel('Condition')\n",
    "            \n",
    "        plt.ylabel('Relative Fisher Information')\n",
    "        plt.title('Relative Impact of Noise Correlations')\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    return fi_full, fi_diag, fi_uniform\n",
    "\n",
    "# Compare FI under different correlation assumptions\n",
    "fi_full, fi_diag, fi_uniform = compare_fi_correlation_impact(\n",
    "    interp_mu, interp_sigma, mu_grad, sigma_grad, interp_conditions\n",
    ")\n",
    "\n",
    "# %% Summary of analysis\n",
    "\n",
    "print(\"=== Fisher Information Analysis Complete ===\")\n",
    "print(f\"- Analyzed data across {interp_conditions.shape[0]} conditions\")\n",
    "print(f\"- Peak Fisher Information: {jnp.max(fi):.4f}\")\n",
    "print(f\"- Average Fisher Information: {jnp.mean(fi):.4f}\")\n",
    "print(\"\\nKey Findings:\")\n",
    "print(f\"- Mean Contribution: {jnp.mean(fi_mean/fi*100):.1f}% of total FI on average\")\n",
    "print(f\"- Covariance Contribution: {jnp.mean(fi_cov/fi*100):.1f}% of total FI on average\")\n",
    "print(f\"- Impact of removing correlations: {jnp.mean(fi_diag/fi_full):.2f}x change in FI on average\")\n",
    "\n",
    "# %% Save results\n",
    "def save_fi_results(fi, conditions, prefix=\"fi_results\"):\n",
    "    \"\"\"Save Fisher Information results to disk\"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists('results'):\n",
    "        os.makedirs('results')\n",
    "    \n",
    "    # Convert to numpy for saving\n",
    "    fi_np = np.array(fi)\n",
    "    conditions_np = np.array(conditions)\n",
    "    \n",
    "    # Save\n",
    "    np.save(f'results/{prefix}_fi.npy', fi_np)\n",
    "    np.save(f'results/{"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wishart",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
